{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Train_Cassava.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfQ6rXBrvPLB",
        "outputId": "5834593c-27f4-496b-a7cb-560477f65233"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Mar  1 15:10:28 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   50C    P0    37W / 250W |  15981MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "metadata": {
        "id": "3wJbk33PvU3I"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud config set project alecsharpie\n",
        "!gcloud config list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KcohofJGhnJb",
        "outputId": "b2dc1868-8ba1-4b1b-fe48-92d3e477bd4d"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated property [core/project].\n",
            "[component_manager]\n",
            "disable_update_check = True\n",
            "[compute]\n",
            "gce_metadata_read_timeout_sec = 0\n",
            "[core]\n",
            "account = alecsharpie@gmail.com\n",
            "project = alecsharpie\n",
            "\n",
            "Your active configuration is: [default]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!echo \"deb http://packages.cloud.google.com/apt gcsfuse-bionic main\" > /etc/apt/sources.list.d/gcsfuse.list\n",
        "!curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -\n",
        "!apt -qq update\n",
        "!apt -qq install gcsfuse"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DKsaB8CEhOD",
        "outputId": "e533e181-7f60-45af-eefd-a5afb1c83892"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  2537  100  2537    0     0   137k      0 --:--:-- --:--:-- --:--:--  137k\n",
            "OK\n",
            "69 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "gcsfuse is already the newest version (0.40.0).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-470\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 69 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir gcs_bucket\n",
        "!gcsfuse --implicit-dirs image-datasets-alecsharpie gcs_bucket"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4JIKQKIvE6jZ",
        "outputId": "c0ce9e4a-9bd8-49f7-a4aa-1175bbb0db23"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘gcs_bucket’: File exists\n",
            "2022/03/01 15:10:38.687281 Start gcsfuse/0.40.0 (Go version go1.17.6) for app \"\" using mount point: /content/gcs_bucket\n",
            "2022/03/01 15:10:38.700758 Opening GCS connection...\n",
            "2022/03/01 15:10:39.119961 Mounting file system \"image-datasets-alecsharpie\"...\n",
            "2022/03/01 15:10:39.120898 File system has been successfully mounted.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls gcs_bucket"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mv_Dcp23Fh0S",
        "outputId": "46dda5ac-44dc-4e0f-d5b6-05623c0a604f"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cassava_farmer\tpackages\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install git+https://github.com/alecsharpie/cassava_farmer.git --no-cache\n"
      ],
      "metadata": {
        "id": "0aMDb0YMHVl7"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir history\n",
        "!mkdir models"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEyawxwdYPkj",
        "outputId": "e39cc137-c4df-4868-a4d3-14fb44f4db1b"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘history’: File exists\n",
            "mkdir: cannot create directory ‘models’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "\n",
        "def get_image_generator_local(\n",
        "    batch_size,\n",
        "    train_path='raw_data/cassava-leaf-disease-classification/train_images_mid'\n",
        "):\n",
        "\n",
        "\n",
        "    train_ds = image_dataset_from_directory(\n",
        "        train_path,\n",
        "        batch_size=batch_size,\n",
        "        subset='training',\n",
        "        validation_split=.20,\n",
        "        seed=42,\n",
        "        image_size=(512, 512),\n",
        "        shuffle = True\n",
        "    )\n",
        "\n",
        "    class_names = train_ds.class_names\n",
        "\n",
        "    train_size = train_ds.cardinality().numpy()\n",
        "    train_ds = train_ds.unbatch().batch(batch_size)\n",
        "    train_ds = train_ds.repeat()\n",
        "\n",
        "    val_ds = image_dataset_from_directory(train_path,\n",
        "                                          batch_size=32,\n",
        "                                          subset='validation',\n",
        "                                          validation_split=.20,\n",
        "                                          seed=42,\n",
        "                                          image_size=(512, 512),\n",
        "                                          shuffle = True)\n",
        "\n",
        "    val_size = val_ds.cardinality().numpy()\n",
        "    val_ds = val_ds.unbatch().batch(batch_size)\n",
        "    val_ds = val_ds.repeat()\n",
        "    return train_ds, train_size, val_ds, val_size\n"
      ],
      "metadata": {
        "id": "rIGEDt--DY91"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.efficientnet import EfficientNetB0\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Sequential\n",
        "\n",
        "\n",
        "#from tensorflow.config import run_functions_eagerly\n",
        "\n",
        "#from google.cloud import storage\n",
        "\n",
        "\n",
        "def build_aug_eff_model(input_shape, output_classes):\n",
        "\n",
        "    augmentation = Sequential([\n",
        "        layers.RandomContrast(0.2),\n",
        "        layers.RandomRotation(40),\n",
        "        layers.RandomTranslation(0, 0.2),\n",
        "        layers.RandomTranslation(0.2, 0),\n",
        "        layers.RandomZoom(0.2, 0.2),\n",
        "        layers.RandomFlip(mode=\"horizontal\")\n",
        "    ])\n",
        "\n",
        "    dummy_input = layers.Input(shape=input_shape)\n",
        "\n",
        "    topless_efficient_net = EfficientNetB0(include_top=False,\n",
        "                                        weights='imagenet',\n",
        "                                        input_tensor=dummy_input,\n",
        "                                        pooling='max')\n",
        "\n",
        "    aug_eff_model = Sequential([\n",
        "        layers.Resizing(512, 512),\n",
        "        #augmentation,\n",
        "        topless_efficient_net,\n",
        "        layers.Dense(12, activation = 'relu'),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.Dense(output_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    #top3_acc = functools.partial(top_k_categorical_accuracy, k=3)\n",
        "    #top3_acc.__name__ = 'top3_acc'\n",
        "\n",
        "    aug_eff_model.compile(optimizer='adam',\n",
        "                        loss='sparse_categorical_crossentropy',\n",
        "                        metrics=['accuracy'])\n",
        "                        #run_eagerly=True)\n",
        "\n",
        "    aug_eff_model.build((None, 512, 512, 3))\n",
        "    aug_eff_model.summary()\n",
        "\n",
        "    aug_eff_model.layers[2].trainable = False\n",
        "\n",
        "    return aug_eff_model"
      ],
      "metadata": {
        "id": "eA7i209Y3fR0"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from cassava_farmer.data import get_image_generator_local\n",
        "#from cassava_farmer.model import build_aug_eff_model, save_model_to_gcp\n",
        "#from cassava_farmer.gcs import storage_upload_file, storage_upload_folder\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import numpy as np\n",
        "\n",
        "batch_size = 16\n",
        "\n",
        "es = EarlyStopping(patience=20)\n",
        "\n",
        "model = build_aug_eff_model((512, 512, 3), 5)\n",
        "\n",
        "train_ds, train_size, val_ds, val_size = get_image_generator_local(batch_size, 'gcs_bucket/cassava_farmer/train_images')\n",
        "\n",
        "\n",
        "steps_per_epoch = train_size // batch_size\n",
        "validation_steps = val_size // batch_size\n",
        "\n",
        "# steps_per_epoch = 10\n",
        "# validation_steps = 3\n",
        "\n",
        "print('steps_per_epoch: ', steps_per_epoch)\n",
        "print('validation_steps: ', validation_steps)\n",
        "\n",
        "count_map = {\n",
        "    0: 1087,\n",
        "    1: 2189,\n",
        "    2: 2386,\n",
        "    3: 13158,\n",
        "    4: 2577\n",
        "}\n",
        "\n",
        "# balance dataset\n",
        "avg_count = np.array(list(count_map.values())).mean()\n",
        "class_weights = {k: (1 / v) * avg_count for k, v in count_map.items()}\n",
        "\n",
        "history = model.fit(\n",
        "  train_ds,\n",
        "  epochs=50,\n",
        "  #batch_size=batch_size,\n",
        "  class_weight = class_weights,\n",
        "  steps_per_epoch=steps_per_epoch,\n",
        "  validation_data=val_ds,\n",
        "  validation_steps=validation_steps,\n",
        "  validation_batch_size=batch_size,\n",
        "  callbacks=[es]).history\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1Nzso1-zlWw",
        "outputId": "a1cd56f8-3eb6-42e7-cbcc-1c1291a49689"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " resizing_4 (Resizing)       (None, 512, 512, 3)       0         \n",
            "                                                                 \n",
            " efficientnetb0 (Functional)  (None, 1280)             4049571   \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 12)                15372     \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 12)                0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 5)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,065,008\n",
            "Trainable params: 4,022,985\n",
            "Non-trainable params: 42,023\n",
            "_________________________________________________________________\n",
            "Found 21407 files belonging to 5 classes.\n",
            "Using 17126 files for training.\n",
            "Found 21407 files belonging to 5 classes.\n",
            "Using 4281 files for validation.\n",
            "steps_per_epoch:  66\n",
            "validation_steps:  8\n",
            "Epoch 1/50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode."
      ],
      "metadata": {
        "id": "PBjSEyrYPAoe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history['loss'], label = 'train')\n",
        "plt.plot(history['val_loss'], label = 'val')\n",
        "plt.legend();"
      ],
      "metadata": {
        "id": "lZCU3Y94W6li"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "history_file_name = f'history/{datetime.now().strftime(\"history_%Y-%m-%d_%H-%M-%S\")}.json'\n",
        "out_file = open(history_file_name, \"w\")\n",
        "json.dump(history, out_file, indent=\"\")\n",
        "out_file.close()\n",
        "#storage_upload_file(history_file_name)\n",
        "files.download(f\"/content/{history_file_name}]\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#storage_upload_folder('models/aug_eff_model_test')"
      ],
      "metadata": {
        "id": "uZAnbdiiDOQ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('max train accuracy', max(history['accuracy']))\n",
        "print('max val accuracy', max(history['val_accuracy']))"
      ],
      "metadata": {
        "id": "VRW-bKqLAPVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from cassava_farmer.trainer import Trainer\n",
        "# trainer = Trainer('colab')\n",
        "# trainer.train(data_path = 'gcs_bucket/cassava_farmer/train_images')"
      ],
      "metadata": {
        "id": "sE-LrJxNGaTT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('models/aug_eff_model')\n",
        "\n",
        "!zip -r /content/models/eff_model_test_colab.zip /content/models/aug_eff_model\n",
        "\n",
        "from google.colab import files\n",
        "files.download(\"/content/models/eff_model_colab.zip\")"
      ],
      "metadata": {
        "id": "jOujAPUeJ2SD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # load previous history\n",
        "# import json\n",
        "\n",
        "# history = json.load(open('/content/history/history_2022-02-27_16-43-50'))\n",
        "\n",
        "# history"
      ],
      "metadata": {
        "id": "hVmXAU5gbW-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# home made model\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Sequential\n",
        "\n",
        "\n",
        "def build_model():\n",
        "\n",
        "  augmentation = Sequential([\n",
        "          layers.RandomContrast(0.2),\n",
        "          layers.RandomRotation(40),\n",
        "          layers.RandomTranslation(0, 0.2),\n",
        "          layers.RandomTranslation(0.2, 0),\n",
        "          layers.RandomZoom(0.2, 0.2),\n",
        "          layers.RandomFlip(mode=\"horizontal\")\n",
        "      ])\n",
        "\n",
        "\n",
        "  model = Sequential([\n",
        "                      layers.Resizing(512, 512),\n",
        "                      augmentation,\n",
        "                      layers.Conv2D(16, (5, 5), activation = 'relu'),\n",
        "                      layers.MaxPooling2D(4),\n",
        "                      layers.Conv2D(32, (5, 5), activation = 'relu'),\n",
        "                      layers.MaxPooling2D(4),\n",
        "                      layers.Conv2D(64, (5, 5), activation = 'relu'),\n",
        "                      layers.MaxPooling2D(4),\n",
        "                      layers.Flatten(),\n",
        "                      layers.Dense(10, activation = 'relu'),\n",
        "                      layers.Dropout(0.4),\n",
        "                      layers.Dense(5, activation = 'softmax')\n",
        "  ])\n",
        "\n",
        "  model.compile(optimizer = 'adam',\n",
        "                loss = 'sparse_categorical_crossentropy',\n",
        "                metrics = 'accuracy')\n",
        "  return model\n"
      ],
      "metadata": {
        "id": "drkwKPwdNf1N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "sVACBT91PKsB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "label_map = {\n",
        "    '0': 'cassava_bacterial_blight', #1087\n",
        "    '1': 'cassava_brown_streak_disease', #2189\n",
        "    '2': 'cassava_green_mottle', #2386\n",
        "    '3': 'cassava_mosaic_disease', #13158\n",
        "    '4': 'healthy' #2577\n",
        "}\n",
        "\n",
        "count_map = {\n",
        "    '0': 1087,\n",
        "    '1': 2189,\n",
        "    '2': 2386,\n",
        "    '3': 13158,\n",
        "    '4': 2577\n",
        "}\n",
        "\n",
        "# balance dataset\n",
        "avg_count = np.array(list(count_map.values())).mean()\n",
        "class_weights = {k: (1 / v) * avg_count for k, v in count_map.items()}"
      ],
      "metadata": {
        "id": "O93TdP1FREhy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_model = build_model()\n",
        "test_model.build((None, 512, 512, 3))\n",
        "test_model.summary()"
      ],
      "metadata": {
        "id": "a8dB-p-VuOTJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_model = build_model()\n",
        "\n",
        "# history = test_model.fit(\n",
        "#                 train_ds,\n",
        "#                 epochs=1,\n",
        "#                 class_weights = class_weights\n",
        "#                 #batch_size=batch_size,\n",
        "#                 steps_per_epoch=steps_per_epoch,\n",
        "#                 validation_data=val_ds,\n",
        "#                 validation_steps=validation_steps,\n",
        "#                 validation_batch_size=batch_size).history\n",
        "#                 #callbacks=[es]"
      ],
      "metadata": {
        "id": "7qdQMs52Obpy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "EBBaLd9LOgbA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}