{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Train_Cassava.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfQ6rXBrvPLB",
        "outputId": "a8b24b95-be48-45d3-d482-c9c55e74ae82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Feb 28 15:55:14 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   46C    P0    30W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "metadata": {
        "id": "3wJbk33PvU3I"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud config set project alecsharpie\n",
        "!gcloud config list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KcohofJGhnJb",
        "outputId": "9596de2b-8e05-4af1-9f3a-abd7f132a033"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated property [core/project].\n",
            "[component_manager]\n",
            "disable_update_check = True\n",
            "[compute]\n",
            "gce_metadata_read_timeout_sec = 0\n",
            "[core]\n",
            "account = alecsharpie@gmail.com\n",
            "project = alecsharpie\n",
            "\n",
            "Your active configuration is: [default]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!echo \"deb http://packages.cloud.google.com/apt gcsfuse-bionic main\" > /etc/apt/sources.list.d/gcsfuse.list\n",
        "!curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -\n",
        "!apt -qq update\n",
        "!apt -qq install gcsfuse"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DKsaB8CEhOD",
        "outputId": "d3df5058-09e6-44fa-fe35-f0d85ab0ab6a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  2537  100  2537    0     0  70472      0 --:--:-- --:--:-- --:--:-- 70472\n",
            "OK\n",
            "69 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-470\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following NEW packages will be installed:\n",
            "  gcsfuse\n",
            "0 upgraded, 1 newly installed, 0 to remove and 69 not upgraded.\n",
            "Need to get 12.0 MB of archives.\n",
            "After this operation, 28.6 MB of additional disk space will be used.\n",
            "Selecting previously unselected package gcsfuse.\n",
            "(Reading database ... 155320 files and directories currently installed.)\n",
            "Preparing to unpack .../gcsfuse_0.40.0_amd64.deb ...\n",
            "Unpacking gcsfuse (0.40.0) ...\n",
            "Setting up gcsfuse (0.40.0) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir gcs_bucket\n",
        "!gcsfuse --implicit-dirs image-datasets-alecsharpie gcs_bucket"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4JIKQKIvE6jZ",
        "outputId": "8dc85878-55e2-41dd-e4a6-be6da22d02bd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022/02/28 15:55:36.376461 Start gcsfuse/0.40.0 (Go version go1.17.6) for app \"\" using mount point: /content/gcs_bucket\n",
            "2022/02/28 15:55:36.390734 Opening GCS connection...\n",
            "2022/02/28 15:55:36.858356 Mounting file system \"image-datasets-alecsharpie\"...\n",
            "2022/02/28 15:55:36.893614 File system has been successfully mounted.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls gcs_bucket"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mv_Dcp23Fh0S",
        "outputId": "754f4009-c120-48c0-866a-a9b5f1559f55"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cassava_farmer\tpackages\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install git+https://github.com/alecsharpie/cassava_farmer.git --no-cache\n"
      ],
      "metadata": {
        "id": "0aMDb0YMHVl7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir history\n",
        "!mkdir models"
      ],
      "metadata": {
        "id": "OEyawxwdYPkj"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "\n",
        "def get_image_generator_local(\n",
        "    batch_size,\n",
        "    train_path='raw_data/cassava-leaf-disease-classification/train_images_mid'\n",
        "):\n",
        "\n",
        "\n",
        "    train_ds = image_dataset_from_directory(\n",
        "        train_path,\n",
        "        batch_size=batch_size,\n",
        "        subset='training',\n",
        "        validation_split=.20,\n",
        "        seed=42,\n",
        "        image_size=(512, 512),\n",
        "    )\n",
        "\n",
        "    class_names = train_ds.class_names\n",
        "\n",
        "    train_size = train_ds.cardinality().numpy()\n",
        "    train_ds = train_ds.unbatch().batch(batch_size)\n",
        "    train_ds = train_ds.repeat()\n",
        "\n",
        "    val_ds = image_dataset_from_directory(train_path,\n",
        "                                          batch_size=32,\n",
        "                                          subset='validation',\n",
        "                                          validation_split=.20,\n",
        "                                          seed=42,\n",
        "                                          image_size=(512, 512))\n",
        "\n",
        "    val_size = val_ds.cardinality().numpy()\n",
        "    val_ds = val_ds.unbatch().batch(batch_size)\n",
        "    val_ds = val_ds.repeat()\n",
        "    return train_ds, train_size, val_ds, val_size\n",
        "\n",
        "batch_size = 1\n",
        "\n",
        "train_ds, train_size, val_ds, val_size = get_image_generator_local(batch_size, 'gcs_bucket/cassava_farmer/train_images')\n",
        "\n",
        "steps_per_epoch = train_size // batch_size\n",
        "validation_steps = val_size // batch_size\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIGEDt--DY91",
        "outputId": "5c7015bc-5988-480b-964d-41a3575e59c1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 21407 files belonging to 5 classes.\n",
            "Using 17126 files for training.\n",
            "Found 21407 files belonging to 5 classes.\n",
            "Using 4281 files for validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.efficientnet import EfficientNetB0\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Sequential\n",
        "\n",
        "\n",
        "#from tensorflow.config import run_functions_eagerly\n",
        "\n",
        "#from google.cloud import storage\n",
        "\n",
        "\n",
        "def build_aug_eff_model(input_shape, output_classes):\n",
        "\n",
        "    augmentation = Sequential([\n",
        "        layers.RandomContrast(0.2),\n",
        "        layers.RandomRotation(40),\n",
        "        layers.RandomTranslation(0, 0.2),\n",
        "        layers.RandomTranslation(0.2, 0),\n",
        "        layers.RandomZoom(0.2, 0.2),\n",
        "        layers.RandomFlip(mode=\"horizontal\")\n",
        "    ])\n",
        "\n",
        "    dummy_input = layers.Input(shape=input_shape)\n",
        "\n",
        "    topless_efficient_net = EfficientNetB0(include_top=False,\n",
        "                                        weights='imagenet',\n",
        "                                        input_tensor=dummy_input,\n",
        "                                        pooling='max')\n",
        "\n",
        "    aug_eff_model = Sequential([\n",
        "        layers.Resizing(512, 512),\n",
        "        augmentation,\n",
        "        topless_efficient_net,\n",
        "        layers.Dropout(0.2),\n",
        "        layers.Dense(output_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    #top3_acc = functools.partial(top_k_categorical_accuracy, k=3)\n",
        "    #top3_acc.__name__ = 'top3_acc'\n",
        "\n",
        "    aug_eff_model.compile(optimizer='adam',\n",
        "                        loss='sparse_categorical_crossentropy',\n",
        "                        metrics=['accuracy'])\n",
        "                        #run_eagerly=True)\n",
        "\n",
        "    aug_eff_model.build((None, 512, 512, 3))\n",
        "    aug_eff_model.summary()\n",
        "\n",
        "    aug_eff_model.layers[2].trainable = False\n",
        "\n",
        "    return aug_eff_model"
      ],
      "metadata": {
        "id": "eA7i209Y3fR0"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "6seVKeSMeetL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from cassava_farmer.data import get_image_generator_local\n",
        "#from cassava_farmer.model import build_aug_eff_model, save_model_to_gcp\n",
        "#from cassava_farmer.gcs import storage_upload_file, storage_upload_folder\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "es = EarlyStopping(patience=10)\n",
        "\n",
        "model = build_aug_eff_model((512, 512, 3), 5)\n",
        "\n",
        "train_ds, train_size, val_ds, val_size = get_image_generator_local(8, 'gcs_bucket/cassava_farmer/train_images')\n",
        "batch_size = 8\n",
        "\n",
        "steps_per_epoch = train_size // batch_size\n",
        "validation_steps = val_size // batch_size\n",
        "\n",
        "# steps_per_epoch = 10\n",
        "# validation_steps = 3\n",
        "\n",
        "print('steps_per_epoch: ', steps_per_epoch)\n",
        "print('validation_steps: ', validation_steps)\n",
        "\n",
        "count_map = {\n",
        "    '0': 1087,\n",
        "    '1': 2189,\n",
        "    '2': 2386,\n",
        "    '3': 13158,\n",
        "    '4': 2577\n",
        "}\n",
        "\n",
        "# balance dataset\n",
        "avg_count = np.array(list(count_map.values())).mean()\n",
        "class_weights = {k: (1 / v) * avg_count for k, v in count_map.items()}\n",
        "\n",
        "history = model.fit(\n",
        "  train_ds,\n",
        "  epochs=100,\n",
        "  #batch_size=batch_size,\n",
        "  class_weight = class_weights,\n",
        "  steps_per_epoch=steps_per_epoch,\n",
        "  validation_data=val_ds,\n",
        "  validation_steps=validation_steps,\n",
        "  validation_batch_size=batch_size,\n",
        "  callbacks=[es]).history\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 817
        },
        "id": "b1Nzso1-zlWw",
        "outputId": "da4667af-2b37-4f2f-b98e-919241517ec8"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " resizing_6 (Resizing)       (None, 512, 512, 3)       0         \n",
            "                                                                 \n",
            " sequential_12 (Sequential)  (None, 512, 512, 3)       0         \n",
            "                                                                 \n",
            " efficientnetb0 (Functional)  (None, 1280)             4049571   \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 1280)              0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 5)                 6405      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,055,976\n",
            "Trainable params: 4,013,953\n",
            "Non-trainable params: 42,023\n",
            "_________________________________________________________________\n",
            "Found 21407 files belonging to 5 classes.\n",
            "Using 17126 files for training.\n",
            "Found 21407 files belonging to 5 classes.\n",
            "Using 4281 files for validation.\n",
            "steps_per_epoch:  267\n",
            "validation_steps:  16\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-3c3fb060d0d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m   \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m   \u001b[0mvalidation_batch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m   callbacks=[es]).history\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_make_class_weight_map_fn\u001b[0;34m(class_weight)\u001b[0m\n\u001b[1;32m   1420\u001b[0m         \u001b[0;34m\"Expected `class_weight` to be a dict with keys from 0 to one less \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1421\u001b[0m         \"than the number of classes, found {}\").format(class_weight)\n\u001b[0;32m-> 1422\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1424\u001b[0m   class_weight_tensor = tf.convert_to_tensor(\n",
            "\u001b[0;31mValueError\u001b[0m: Expected `class_weight` to be a dict with keys from 0 to one less than the number of classes, found {'0': 3.9368905243790246, '1': 1.9549566011877568, '2': 1.7935456831517183, '3': 0.32523179814561476, '4': 1.660613116026387}"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history['loss'], label = 'train')\n",
        "plt.plot(history['val_loss'], label = 'val')\n",
        "plt.legend();"
      ],
      "metadata": {
        "id": "lZCU3Y94W6li"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "history_file_name = f'history/{datetime.now().strftime(\"history_%Y-%m-%d_%H-%M-%S\")}.json'\n",
        "out_file = open(history_file_name, \"w\")\n",
        "json.dump(history, out_file, indent=\"\")\n",
        "out_file.close()\n",
        "#storage_upload_file(history_file_name)\n",
        "\n",
        "\n",
        "print(history)\n",
        "print('min accuracy', min(history['accuracy']))\n",
        "\n",
        "model.save('models/aug_eff_model_test')\n",
        "\n",
        "#storage_upload_folder('models/aug_eff_model_test')"
      ],
      "metadata": {
        "id": "uZAnbdiiDOQ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from cassava_farmer.trainer import Trainer\n",
        "# trainer = Trainer('colab')\n",
        "# trainer.train(data_path = 'gcs_bucket/cassava_farmer/train_images')"
      ],
      "metadata": {
        "id": "sE-LrJxNGaTT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/models/aug_eff_model_test_colab3.zip /content/models/aug_eff_model_test\n",
        "\n",
        "from google.colab import files\n",
        "files.download(\"/content/models/aug_eff_model_test_colab3.zip\")"
      ],
      "metadata": {
        "id": "jOujAPUeJ2SD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load previous history\n",
        "import json\n",
        "\n",
        "history = json.load(open('/content/history/history_2022-02-27_16-43-50'))\n",
        "\n",
        "history"
      ],
      "metadata": {
        "id": "hVmXAU5gbW-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# home made model\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Sequential\n",
        "\n",
        "\n",
        "def build_model():\n",
        "\n",
        "  augmentation = Sequential([\n",
        "          layers.RandomContrast(0.2),\n",
        "          layers.RandomRotation(40),\n",
        "          layers.RandomTranslation(0, 0.2),\n",
        "          layers.RandomTranslation(0.2, 0),\n",
        "          layers.RandomZoom(0.2, 0.2),\n",
        "          layers.RandomFlip(mode=\"horizontal\")\n",
        "      ])\n",
        "\n",
        "\n",
        "  model = Sequential([\n",
        "                      layers.Resizing(512, 512),\n",
        "                      augmentation,\n",
        "                      layers.Conv2D(16, (5, 5), activation = 'relu'),\n",
        "                      layers.MaxPooling2D(4),\n",
        "                      layers.Conv2D(32, (5, 5), activation = 'relu'),\n",
        "                      layers.MaxPooling2D(4),\n",
        "                      layers.Conv2D(64, (5, 5), activation = 'relu'),\n",
        "                      layers.MaxPooling2D(4),\n",
        "                      layers.Flatten(),\n",
        "                      layers.Dense(10, activation = 'relu'),\n",
        "                      layers.Dropout(0.4),\n",
        "                      layers.Dense(5, activation = 'softmax')\n",
        "  ])\n",
        "\n",
        "  model.compile(optimizer = 'adam',\n",
        "                loss = 'sparse_categorical_crossentropy',\n",
        "                metrics = 'accuracy')\n",
        "  return model\n"
      ],
      "metadata": {
        "id": "drkwKPwdNf1N"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sVACBT91PKsB",
        "outputId": "51446a11-48c5-44fb-fe36-ae8708b025b7"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 21407 files belonging to 5 classes.\n",
            "Using 17126 files for training.\n",
            "Found 21407 files belonging to 5 classes.\n",
            "Using 4281 files for validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "label_map = {\n",
        "    '0': 'cassava_bacterial_blight', #1087\n",
        "    '1': 'cassava_brown_streak_disease', #2189\n",
        "    '2': 'cassava_green_mottle', #2386\n",
        "    '3': 'cassava_mosaic_disease', #13158\n",
        "    '4': 'healthy' #2577\n",
        "}\n",
        "\n",
        "count_map = {\n",
        "    '0': 1087,\n",
        "    '1': 2189,\n",
        "    '2': 2386,\n",
        "    '3': 13158,\n",
        "    '4': 2577\n",
        "}\n",
        "\n",
        "# balance dataset\n",
        "avg_count = np.array(list(count_map.values())).mean()\n",
        "class_weights = {k: (1 / v) * avg_count for k, v in count_map.items()}"
      ],
      "metadata": {
        "id": "O93TdP1FREhy"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_model = build_model()\n",
        "test_model.build((None, 512, 512, 3))\n",
        "test_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8dB-p-VuOTJ",
        "outputId": "266c6b46-fd59-458a-befe-edbc9fcd1613"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " resizing_3 (Resizing)       (None, 512, 512, 3)       0         \n",
            "                                                                 \n",
            " sequential_7 (Sequential)   (None, 512, 512, 3)       0         \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 508, 508, 16)      1216      \n",
            "                                                                 \n",
            " max_pooling2d_9 (MaxPooling  (None, 127, 127, 16)     0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 123, 123, 32)      12832     \n",
            "                                                                 \n",
            " max_pooling2d_10 (MaxPoolin  (None, 30, 30, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 26, 26, 64)        51264     \n",
            "                                                                 \n",
            " max_pooling2d_11 (MaxPoolin  (None, 6, 6, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 2304)              0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 10)                23050     \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 10)                0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 5)                 55        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 88,417\n",
            "Trainable params: 88,417\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_model = build_model()\n",
        "\n",
        "# history = test_model.fit(\n",
        "#                 train_ds,\n",
        "#                 epochs=1,\n",
        "#                 class_weights = class_weights\n",
        "#                 #batch_size=batch_size,\n",
        "#                 steps_per_epoch=steps_per_epoch,\n",
        "#                 validation_data=val_ds,\n",
        "#                 validation_steps=validation_steps,\n",
        "#                 validation_batch_size=batch_size).history\n",
        "#                 #callbacks=[es]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qdQMs52Obpy",
        "outputId": "4f3b83e9-c447-404b-efa3-902cb1ff4edd"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "17126/17126 [==============================] - 1396s 81ms/step - loss: 1.2122 - accuracy: 0.6177 - val_loss: 1.2476 - val_accuracy: 0.5896\n",
            "Epoch 2/3\n",
            "17126/17126 [==============================] - 1401s 82ms/step - loss: 1.2273 - accuracy: 0.6179 - val_loss: 1.2384 - val_accuracy: 0.5896\n",
            "Epoch 3/3\n",
            "17126/17126 [==============================] - 521s 30ms/step - loss: 1.1787 - accuracy: 0.6179 - val_loss: 1.1889 - val_accuracy: 0.6194\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "EBBaLd9LOgbA"
      },
      "execution_count": 41,
      "outputs": []
    }
  ]
}