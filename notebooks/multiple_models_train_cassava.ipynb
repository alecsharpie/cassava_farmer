{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Train_Cassava.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfQ6rXBrvPLB",
        "outputId": "9741204d-54e6-4f37-daec-6b09a0fdadb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Mar  3 04:21:19 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "metadata": {
        "id": "3wJbk33PvU3I"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud config set project alecsharpie\n",
        "!gcloud config list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KcohofJGhnJb",
        "outputId": "2b427d60-e7ef-43a8-d6e9-cda45418fb3b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated property [core/project].\n",
            "[component_manager]\n",
            "disable_update_check = True\n",
            "[compute]\n",
            "gce_metadata_read_timeout_sec = 0\n",
            "[core]\n",
            "account = alecsharpie@gmail.com\n",
            "project = alecsharpie\n",
            "\n",
            "Your active configuration is: [default]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!echo \"deb http://packages.cloud.google.com/apt gcsfuse-bionic main\" > /etc/apt/sources.list.d/gcsfuse.list\n",
        "!curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -\n",
        "!apt -qq update\n",
        "!apt -qq install gcsfuse"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DKsaB8CEhOD",
        "outputId": "0c6eebc9-bec0-4b68-f746-e4f633cb1095"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  2537  100  2537    0     0    99k      0 --:--:-- --:--:-- --:--:--   99k\n",
            "OK\n",
            "75 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "gcsfuse is already the newest version (0.40.0).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-470\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 75 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir gcs_bucket\n",
        "!gcsfuse --implicit-dirs image-datasets-alecsharpie gcs_bucket"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4JIKQKIvE6jZ",
        "outputId": "ef2af844-c743-4f82-fdda-8dc6ce13477e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘gcs_bucket’: File exists\n",
            "2022/03/03 04:21:28.310706 Start gcsfuse/0.40.0 (Go version go1.17.6) for app \"\" using mount point: /content/gcs_bucket\n",
            "2022/03/03 04:21:28.326119 Opening GCS connection...\n",
            "2022/03/03 04:21:28.466621 Mounting file system \"image-datasets-alecsharpie\"...\n",
            "daemonize.Run: readFromProcess: sub-process: mountWithArgs: mountWithConn: Mount: Statting mount point: stat /content/gcs_bucket: transport endpoint is not connected\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls gcs_bucket"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mv_Dcp23Fh0S",
        "outputId": "9d61c996-01c1-4535-f45f-d1f67d11104e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access 'gcs_bucket': Transport endpoint is not connected\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install git+https://github.com/alecsharpie/cassava_farmer.git --no-cache\n"
      ],
      "metadata": {
        "id": "0aMDb0YMHVl7"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir history\n",
        "!mkdir models"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OEyawxwdYPkj",
        "outputId": "826e5fce-26f6-48a0-b9e9-3e5c9b08cadf"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘history’: File exists\n",
            "mkdir: cannot create directory ‘models’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "\n",
        "def get_image_generator_local(\n",
        "    batch_size,\n",
        "    train_path='raw_data/cassava-leaf-disease-classification/train_images_mid'\n",
        "):\n",
        "\n",
        "\n",
        "    train_ds = image_dataset_from_directory(\n",
        "        train_path,\n",
        "        batch_size=batch_size,\n",
        "        subset='training',\n",
        "        validation_split=.20,\n",
        "        seed=42,\n",
        "        image_size=(512, 512),\n",
        "        shuffle = True\n",
        "    )\n",
        "\n",
        "    class_names = train_ds.class_names\n",
        "\n",
        "    train_size = train_ds.cardinality().numpy()\n",
        "    #train_ds = train_ds.unbatch().batch(batch_size)\n",
        "    #train_ds = train_ds.repeat()\n",
        "\n",
        "    val_ds = image_dataset_from_directory(train_path,\n",
        "                                          batch_size=32,\n",
        "                                          subset='validation',\n",
        "                                          validation_split=.20,\n",
        "                                          seed=42,\n",
        "                                          image_size=(512, 512),\n",
        "                                          shuffle = True)\n",
        "\n",
        "    val_size = val_ds.cardinality().numpy()\n",
        "    #val_ds = val_ds.unbatch().batch(batch_size)\n",
        "    #val_ds = val_ds.repeat()\n",
        "    return train_ds, train_size, val_ds, val_size\n"
      ],
      "metadata": {
        "id": "rIGEDt--DY91"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.efficientnet import EfficientNetB0\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "\n",
        "#from tensorflow.config import run_functions_eagerly\n",
        "\n",
        "#from google.cloud import storage\n",
        "\n",
        "\n",
        "def build_aug_eff_model(input_shape, output_classes):\n",
        "\n",
        "    augmentation = Sequential([\n",
        "        layers.RandomContrast(0.2),\n",
        "        layers.RandomRotation(40),\n",
        "        layers.RandomTranslation(0, 0.2),\n",
        "        layers.RandomTranslation(0.2, 0),\n",
        "        layers.RandomZoom(0.2, 0.2),\n",
        "        layers.RandomFlip(mode=\"horizontal\")\n",
        "    ])\n",
        "\n",
        "    dummy_input = layers.Input(shape=input_shape)\n",
        "\n",
        "    topless_efficient_net = EfficientNetB0(include_top=False,\n",
        "                                        weights='imagenet',\n",
        "                                        input_tensor=dummy_input,\n",
        "                                        pooling='max')\n",
        "\n",
        "    aug_eff_model = Sequential([\n",
        "        layers.Resizing(512, 512),\n",
        "        #augmentation,\n",
        "        topless_efficient_net,\n",
        "        layers.Dense(12, activation = 'relu'),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.Dense(output_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    #top3_acc = functools.partial(top_k_categorical_accuracy, k=3)\n",
        "    #top3_acc.__name__ = 'top3_acc'\n",
        "\n",
        "\n",
        "    aug_eff_model.compile(optimizer=Adam(),\n",
        "                        loss='sparse_categorical_crossentropy',\n",
        "                        metrics=['accuracy'])\n",
        "                        #run_eagerly=True)\n",
        "\n",
        "    aug_eff_model.build((None, 512, 512, 3))\n",
        "    aug_eff_model.summary()\n",
        "\n",
        "    aug_eff_model.layers[2].trainable = False\n",
        "\n",
        "    return aug_eff_model"
      ],
      "metadata": {
        "id": "eA7i209Y3fR0"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# home made model\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Sequential\n",
        "\n",
        "\n",
        "def build_model():\n",
        "\n",
        "  augmentation = Sequential([\n",
        "          layers.RandomContrast(0.2),\n",
        "          layers.RandomRotation(40),\n",
        "          layers.RandomTranslation(0, 0.2),\n",
        "          layers.RandomTranslation(0.2, 0),\n",
        "          layers.RandomZoom(0.2, 0.2),\n",
        "          layers.RandomFlip(mode=\"horizontal\")\n",
        "      ])\n",
        "\n",
        "\n",
        "  model = Sequential([layers.Rescaling(1./255),\n",
        "                      #layers.Resizing(256, 256),\n",
        "                      #augmentation,\n",
        "                      layers.Conv2D(16, (24, 24), activation = 'relu'),\n",
        "                      layers.MaxPooling2D(2),\n",
        "                      layers.Conv2D(32, (12, 12), activation = 'relu'),\n",
        "                      layers.MaxPooling2D(2),\n",
        "                      layers.Conv2D(64, (6, 6), activation = 'relu'),\n",
        "                      layers.MaxPooling2D(2),\n",
        "                      layers.Conv2D(128, (5, 5), activation = 'relu'),\n",
        "                      layers.MaxPooling2D(2),\n",
        "                      layers.Flatten(),\n",
        "                      layers.Dense(100, activation = 'relu'),\n",
        "                      layers.Dropout(0.3),\n",
        "                      layers.Dense(10, activation = 'relu'),\n",
        "                      layers.Dropout(0.4),\n",
        "                      layers.Dense(5, activation = 'softmax')\n",
        "  ])\n",
        "\n",
        "  model.compile(optimizer = Adam(learning_rate=0.0000001),\n",
        "                loss = 'sparse_categorical_crossentropy',\n",
        "                metrics = 'accuracy',\n",
        "                run_eagerly=True)\n",
        "  \n",
        "\n",
        "  model.build((None, 512, 512, 3))\n",
        "  model.summary()\n",
        "\n",
        "  return model\n"
      ],
      "metadata": {
        "id": "vEqsrXCrXFx4"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DfD1e37AT7Ln",
        "outputId": "b2d21bdf-d1c4-4ea6-8991-9cdea8686b6e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " rescaling (Rescaling)       (None, 512, 512, 3)       0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 489, 489, 16)      27664     \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 244, 244, 16)     0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 233, 233, 32)      73760     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 116, 116, 32)     0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 111, 111, 64)      73792     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 55, 55, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 51, 51, 128)       204928    \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 25, 25, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 80000)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 100)               8000100   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 100)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                1010      \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 10)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 5)                 55        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 8,381,309\n",
            "Trainable params: 8,381,309\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# home made model\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Sequential\n",
        "\n",
        "\n",
        "def build_simple_model():\n",
        "\n",
        "  model = Sequential([#layers.Rescaling(1./255),\n",
        "                      layers.Conv2D(32, (12, 12), activation = 'relu'),\n",
        "                      layers.MaxPooling2D(2),\n",
        "                      layers.Conv2D(64, (6, 6), activation = 'relu'),\n",
        "                      layers.MaxPooling2D(2),\n",
        "                      layers.Flatten(),\n",
        "                      layers.Dense(10, activation = 'relu'),\n",
        "                      layers.Dropout(0.4),\n",
        "                      layers.Dense(5, activation = 'softmax')\n",
        "  ])\n",
        "\n",
        "  model.compile(optimizer = Adam(learning_rate=0.001),\n",
        "                loss = 'sparse_categorical_crossentropy',\n",
        "                metrics = 'accuracy',\n",
        "                run_eagerly=True)\n",
        "  \n",
        "\n",
        "  #model.build((None, 512, 512, 3))\n",
        "  #model.summary()\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "Uf3LhEQHS2FU"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from cassava_farmer.data import get_image_generator_local\n",
        "#from cassava_farmer.model import build_aug_eff_model, save_model_to_gcp\n",
        "#from cassava_farmer.gcs import storage_upload_file, storage_upload_folder\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import numpy as np\n",
        "\n",
        "batch_size = 8\n",
        "\n",
        "es = EarlyStopping(patience=10)\n",
        "\n",
        "model = build_aug_eff_model((512, 512, 3), 5)\n",
        "#model = build_model()\n",
        "#model = build_simple_model()\n",
        "\n",
        "train_ds, train_size, val_ds, val_size = get_image_generator_local(batch_size, 'gcs_bucket/cassava_farmer/train_images')\n",
        "\n",
        "\n",
        "steps_per_epoch = train_size // batch_size\n",
        "validation_steps = val_size // batch_size\n",
        "\n",
        "# steps_per_epoch = 10\n",
        "# validation_steps = 3\n",
        "\n",
        "print('steps_per_epoch: ', steps_per_epoch)\n",
        "print('validation_steps: ', validation_steps)\n",
        "\n",
        "count_map = {\n",
        "    0: 1087,\n",
        "    1: 2189,\n",
        "    2: 2386,\n",
        "    3: 13158,\n",
        "    4: 2577\n",
        "}\n",
        "\n",
        "# balance dataset\n",
        "avg_count = np.array(list(count_map.values())).mean()\n",
        "class_weights = {k: (1 / v) * avg_count for k, v in count_map.items()}\n",
        "\n",
        "history = model.fit(\n",
        "  train_ds,\n",
        "  epochs=50,\n",
        "  #batch_size=batch_size,\n",
        "  #class_weight = class_weights,\n",
        "  steps_per_epoch=steps_per_epoch,\n",
        "  #validation_data=val_ds,\n",
        "  #validation_steps=validation_steps,\n",
        "  #validation_batch_size=batch_size,\n",
        "  #callbacks=[es]\n",
        "  ).history\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 764
        },
        "id": "b1Nzso1-zlWw",
        "outputId": "14d72d78-19c2-462c-9b40-425bd822861e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " resizing (Resizing)         (None, 512, 512, 3)       0         \n",
            "                                                                 \n",
            " efficientnetb0 (Functional)  (None, 1280)             4049571   \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 12)                15372     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 12)                0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 5)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,065,008\n",
            "Trainable params: 4,022,985\n",
            "Non-trainable params: 42,023\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-1189b1815d55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m#model = build_simple_model()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_image_generator_local\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'gcs_bucket/cassava_farmer/train_images'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-6fafd3201bf1>\u001b[0m in \u001b[0;36mget_image_generator_local\u001b[0;34m(batch_size, train_path)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mimage_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     )\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/preprocessing/image_dataset.py\u001b[0m in \u001b[0;36mimage_dataset_from_directory\u001b[0;34m(directory, labels, label_mode, class_names, color_mode, batch_size, image_size, shuffle, seed, validation_split, subset, interpolation, follow_links, crop_to_aspect_ratio, **kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m       \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m       \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m       follow_links=follow_links)\n\u001b[0m\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mlabel_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'binary'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/preprocessing/dataset_utils.py\u001b[0m in \u001b[0;36mindex_directory\u001b[0;34m(directory, labels, formats, class_names, shuffle, seed, follow_links)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0msubdirs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0msubdirs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: [Errno 107] Transport endpoint is not connected: 'gcs_bucket/cassava_farmer/train_images'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "nk6oj2c2S8LQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode."
      ],
      "metadata": {
        "id": "PBjSEyrYPAoe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history['loss'], label = 'train')\n",
        "#plt.plot(history['val_loss'], label = 'val')\n",
        "plt.legend();"
      ],
      "metadata": {
        "id": "lZCU3Y94W6li"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "y_pred = model.predict(train_ds.take(100))"
      ],
      "metadata": {
        "id": "tZfomkalqAzw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test_batch = train_ds.take(100)\n",
        "#test_batch[1]"
      ],
      "metadata": {
        "id": "hjZrJUCk95va"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#list(train_ds.as_numpy_iterator())[0]"
      ],
      "metadata": {
        "id": "ayjpcgWp-RdZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds.get_single_element()"
      ],
      "metadata": {
        "id": "UhifSll2_g73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred"
      ],
      "metadata": {
        "id": "rR7jOyIX9PNz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "5MNZOdfK_gRD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classification_report(y_pred, )"
      ],
      "metadata": {
        "id": "Bj-pH10A5NfN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from datetime import datetime\n",
        "from google.colab import files\n",
        "\n",
        "history_file_name = f'history/{datetime.now().strftime(\"history_%Y-%m-%d_%H-%M-%S\")}.json'\n",
        "out_file = open(history_file_name, \"w\")\n",
        "json.dump(history, out_file, indent=\"\")\n",
        "out_file.close()\n",
        "#storage_upload_file(history_file_name)\n",
        "files.download(f\"/content/{history_file_name}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#storage_upload_folder('models/aug_eff_model_test')"
      ],
      "metadata": {
        "id": "uZAnbdiiDOQ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('max train accuracy', max(history['accuracy']))\n",
        "print('max val accuracy', max(history['val_accuracy']))"
      ],
      "metadata": {
        "id": "VRW-bKqLAPVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from cassava_farmer.trainer import Trainer\n",
        "# trainer = Trainer('colab')\n",
        "# trainer.train(data_path = 'gcs_bucket/cassava_farmer/train_images')"
      ],
      "metadata": {
        "id": "sE-LrJxNGaTT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('models/aug_eff_model')\n",
        "\n",
        "!zip -r /content/models/eff_model_colab.zip /content/models/aug_eff_model\n",
        "\n",
        "\n",
        "files.download(\"/content/models/eff_model_colab.zip\")"
      ],
      "metadata": {
        "id": "jOujAPUeJ2SD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # load previous history\n",
        "# import json\n",
        "\n",
        "# history = json.load(open('/content/history/history_2022-02-27_16-43-50'))\n",
        "\n",
        "# history"
      ],
      "metadata": {
        "id": "hVmXAU5gbW-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "label_map = {\n",
        "    '0': 'cassava_bacterial_blight', #1087\n",
        "    '1': 'cassava_brown_streak_disease', #2189\n",
        "    '2': 'cassava_green_mottle', #2386\n",
        "    '3': 'cassava_mosaic_disease', #13158\n",
        "    '4': 'healthy' #2577\n",
        "}\n",
        "\n",
        "count_map = {\n",
        "    '0': 1087,\n",
        "    '1': 2189,\n",
        "    '2': 2386,\n",
        "    '3': 13158,\n",
        "    '4': 2577\n",
        "}\n",
        "\n",
        "# balance dataset\n",
        "avg_count = np.array(list(count_map.values())).mean()\n",
        "class_weights = {k: (1 / v) * avg_count for k, v in count_map.items()}"
      ],
      "metadata": {
        "id": "O93TdP1FREhy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_model = build_model()\n",
        "test_model.build((None, 512, 512, 3))\n",
        "test_model.summary()"
      ],
      "metadata": {
        "id": "a8dB-p-VuOTJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_model = build_model()\n",
        "\n",
        "# history = test_model.fit(\n",
        "#                 train_ds,\n",
        "#                 epochs=1,\n",
        "#                 class_weights = class_weights\n",
        "#                 #batch_size=batch_size,\n",
        "#                 steps_per_epoch=steps_per_epoch,\n",
        "#                 validation_data=val_ds,\n",
        "#                 validation_steps=validation_steps,\n",
        "#                 validation_batch_size=batch_size).history\n",
        "#                 #callbacks=[es]"
      ],
      "metadata": {
        "id": "7qdQMs52Obpy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "EBBaLd9LOgbA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}