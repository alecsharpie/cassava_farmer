{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "multiple_models_train_cassava.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dfQ6rXBrvPLB"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "metadata": {
        "id": "3wJbk33PvU3I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud config set project alecsharpie\n",
        "!gcloud config list"
      ],
      "metadata": {
        "id": "KcohofJGhnJb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!echo \"deb http://packages.cloud.google.com/apt gcsfuse-bionic main\" > /etc/apt/sources.list.d/gcsfuse.list\n",
        "!curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -\n",
        "!apt -qq update\n",
        "!apt -qq install gcsfuse"
      ],
      "metadata": {
        "id": "7DKsaB8CEhOD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir gcs_bucket\n",
        "!gcsfuse --implicit-dirs image-datasets-alecsharpie gcs_bucket"
      ],
      "metadata": {
        "id": "4JIKQKIvE6jZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls gcs_bucket"
      ],
      "metadata": {
        "id": "mv_Dcp23Fh0S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install git+https://github.com/alecsharpie/cassava_farmer.git --no-cache\n"
      ],
      "metadata": {
        "id": "0aMDb0YMHVl7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir history\n",
        "!mkdir models"
      ],
      "metadata": {
        "id": "OEyawxwdYPkj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "\n",
        "def get_image_generator_local(\n",
        "    batch_size,\n",
        "    train_path='raw_data/cassava-leaf-disease-classification/train_images_mid'\n",
        "):\n",
        "\n",
        "\n",
        "    train_ds = image_dataset_from_directory(\n",
        "        train_path,\n",
        "        batch_size=batch_size,\n",
        "        subset='training',\n",
        "        validation_split=.20,\n",
        "        seed=32,\n",
        "        image_size=(512, 512),\n",
        "        shuffle = True\n",
        "    )\n",
        "\n",
        "    class_names = train_ds.class_names\n",
        "\n",
        "    train_size = train_ds.cardinality().numpy()\n",
        "    #train_ds = train_ds.unbatch().batch(batch_size)\n",
        "    train_ds = train_ds.repeat()\n",
        "\n",
        "    val_ds = image_dataset_from_directory(train_path,\n",
        "                                          batch_size=batch_size,\n",
        "                                          subset='validation',\n",
        "                                          validation_split=.20,\n",
        "                                          seed=32,\n",
        "                                          image_size=(512, 512),\n",
        "                                          shuffle = True)\n",
        "\n",
        "    val_size = val_ds.cardinality().numpy()\n",
        "    #val_ds = val_ds.unbatch().batch(batch_size)\n",
        "    val_ds = val_ds.repeat()\n",
        "    return train_ds, train_size, val_ds, val_size\n"
      ],
      "metadata": {
        "id": "rIGEDt--DY91"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.efficientnet import EfficientNetB0\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "\n",
        "#from tensorflow.config import run_functions_eagerly\n",
        "\n",
        "#from google.cloud import storage\n",
        "\n",
        "\n",
        "def build_aug_eff_model(input_shape, output_classes):\n",
        "\n",
        "    augmentation = Sequential([\n",
        "        layers.RandomContrast(0.2),\n",
        "        layers.RandomRotation(40),\n",
        "        layers.RandomTranslation(0, 0.2),\n",
        "        layers.RandomTranslation(0.2, 0),\n",
        "        layers.RandomZoom(0.2, 0.2),\n",
        "        layers.RandomFlip(mode=\"horizontal\")\n",
        "    ])\n",
        "\n",
        "    dummy_input = layers.Input(shape=input_shape)\n",
        "\n",
        "    topless_efficient_net = EfficientNetB0(include_top=False,\n",
        "                                        weights='imagenet',\n",
        "                                        input_tensor=dummy_input,\n",
        "                                        pooling='max')\n",
        "\n",
        "    aug_eff_model = Sequential([\n",
        "        #layers.Resizing(512, 512),\n",
        "        #augmentation,\n",
        "        topless_efficient_net,\n",
        "        layers.Dense(12, activation = 'tanh'),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.Dense(output_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    #top3_acc = functools.partial(top_k_categorical_accuracy, k=3)\n",
        "    #top3_acc.__name__ = 'top3_acc'\n",
        "\n",
        "\n",
        "    aug_eff_model.compile(optimizer=Adam(0.000001),\n",
        "                        loss='sparse_categorical_crossentropy',\n",
        "                        metrics=['accuracy'])\n",
        "                        #run_eagerly=True)\n",
        "\n",
        "    aug_eff_model.build((None, 512, 512, 3))\n",
        "\n",
        "    aug_eff_model.layers[0].trainable = False\n",
        "\n",
        "    # for layer in aug_eff_model.layers:\n",
        "    #   layer.trainable = False\n",
        "\n",
        "    # for layer in aug_eff_model.layers:\n",
        "    #   print(len(layer.trainable_weights))\n",
        "    #   print(len(layer.non_trainable_weights))\n",
        "\n",
        "    aug_eff_model.summary()\n",
        "\n",
        "    return aug_eff_model"
      ],
      "metadata": {
        "id": "eA7i209Y3fR0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "build_aug_eff_model((512, 512, 3), 5)"
      ],
      "metadata": {
        "id": "9yVf62ABH8Ap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# home made model\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Sequential\n",
        "\n",
        "\n",
        "def build_model():\n",
        "\n",
        "  augmentation = Sequential([\n",
        "          layers.RandomContrast(0.2),\n",
        "          layers.RandomRotation(40),\n",
        "          layers.RandomTranslation(0, 0.2),\n",
        "          layers.RandomTranslation(0.2, 0),\n",
        "          layers.RandomZoom(0.2, 0.2),\n",
        "          layers.RandomFlip(mode=\"horizontal\")\n",
        "      ])\n",
        "\n",
        "\n",
        "  model = Sequential([layers.Rescaling(1./255),\n",
        "                      #layers.Resizing(256, 256),\n",
        "                      #augmentation,\n",
        "                      layers.Conv2D(16, (24, 24), activation = 'relu'),\n",
        "                      layers.MaxPooling2D(2),\n",
        "                      layers.Conv2D(32, (12, 12), activation = 'relu'),\n",
        "                      layers.MaxPooling2D(2),\n",
        "                      layers.Conv2D(64, (6, 6), activation = 'relu'),\n",
        "                      layers.MaxPooling2D(2),\n",
        "                      layers.Conv2D(128, (5, 5), activation = 'relu'),\n",
        "                      layers.MaxPooling2D(2),\n",
        "                      layers.Flatten(),\n",
        "                      layers.Dense(100, activation = 'relu'),\n",
        "                      layers.Dropout(0.3),\n",
        "                      layers.Dense(10, activation = 'relu'),\n",
        "                      layers.Dropout(0.4),\n",
        "                      layers.Dense(5, activation = 'softmax')\n",
        "  ])\n",
        "\n",
        "  model.compile(optimizer = Adam(learning_rate=0.0000001),\n",
        "                loss = 'sparse_categorical_crossentropy',\n",
        "                metrics = 'accuracy',\n",
        "                run_eagerly=True)\n",
        "  \n",
        "\n",
        "  model.build((None, 512, 512, 3))\n",
        "  model.summary()\n",
        "\n",
        "  return model\n"
      ],
      "metadata": {
        "id": "vEqsrXCrXFx4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model()\n"
      ],
      "metadata": {
        "id": "DfD1e37AT7Ln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# home made model\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Sequential\n",
        "\n",
        "\n",
        "def build_simple_model():\n",
        "\n",
        "  model = Sequential([#layers.Rescaling(1./255),\n",
        "                      layers.Conv2D(32, (12, 12), activation = 'relu'),\n",
        "                      layers.MaxPooling2D(2),\n",
        "                      layers.Conv2D(64, (6, 6), activation = 'relu'),\n",
        "                      layers.MaxPooling2D(2),\n",
        "                      layers.Flatten(),\n",
        "                      layers.Dense(10, activation = 'relu'),\n",
        "                      layers.Dropout(0.4),\n",
        "                      layers.Dense(5, activation = 'softmax')\n",
        "  ])\n",
        "\n",
        "  model.compile(optimizer = Adam(learning_rate=0.001),\n",
        "                loss = 'sparse_categorical_crossentropy',\n",
        "                metrics = 'accuracy',\n",
        "                run_eagerly=True)\n",
        "  \n",
        "\n",
        "  #model.build((None, 512, 512, 3))\n",
        "  #model.summary()\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "Uf3LhEQHS2FU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "batch_size = 24\n",
        "\n",
        "train_ds, train_size, val_ds, val_size = get_image_generator_local(batch_size, 'gcs_bucket/cassava_farmer/train_images')\n",
        "\n",
        "\n",
        "steps_per_epoch = train_size // batch_size\n",
        "validation_steps = val_size // batch_size\n",
        "\n",
        "# steps_per_epoch = 10\n",
        "# validation_steps = 3\n",
        "\n",
        "print('steps_per_epoch: ', steps_per_epoch)\n",
        "print('validation_steps: ', validation_steps)\n",
        "\n",
        "count_map = {\n",
        "    0: 1087,\n",
        "    1: 2189,\n",
        "    2: 2386,\n",
        "    3: 13158,\n",
        "    4: 2577\n",
        "}\n",
        "\n",
        "# balance dataset\n",
        "avg_count = np.array(list(count_map.values())).mean()\n",
        "class_weights = {k: (1 / v) * avg_count for k, v in count_map.items()}"
      ],
      "metadata": {
        "id": "H1SnaBkwDIpE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "for batch in train_ds.take(1).as_numpy_iterator():\n",
        "  print('X shape: ', batch[0].shape)\n",
        "  print('X min, max: ', np.min(batch[0]), np.max(batch[0]))\n",
        "  fig, axes = plt.subplots(3, 3 , figsize = (15, 15))\n",
        "  for x, y, ax in zip(batch[0], batch[1], axes.flat):\n",
        "    ax.imshow(x /255)\n",
        "    ax.set_title(y)"
      ],
      "metadata": {
        "id": "6zfMtR6pDOx0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for example in train_ds.take(1).as_numpy_iterator():\n",
        "  print('Y: ', example[1].shape)\n",
        "  print('Y: ', example[1])"
      ],
      "metadata": {
        "id": "5ieMKEKLDVSm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from cassava_farmer.data import get_image_generator_local\n",
        "#from cassava_farmer.model import build_aug_eff_model, save_model_to_gcp\n",
        "#from cassava_farmer.gcs import storage_upload_file, storage_upload_folder\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "es = EarlyStopping(patience=200)\n",
        "\n",
        "model = build_aug_eff_model((512, 512, 3), 5)\n",
        "#model = build_model()\n",
        "#model = build_simple_model()\n",
        "\n",
        "history = model.fit(\n",
        "  train_ds,\n",
        "  epochs=800,\n",
        "  #batch_size=batch_size,\n",
        "  class_weight = class_weights,\n",
        "  steps_per_epoch=steps_per_epoch,\n",
        "  validation_data=val_ds,\n",
        "  validation_steps=validation_steps,\n",
        "  validation_batch_size=batch_size,\n",
        "  callbacks=[es]\n",
        "  ).history\n"
      ],
      "metadata": {
        "id": "b1Nzso1-zlWw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history['loss'], label = 'train')\n",
        "plt.plot(history['val_loss'], label = 'val')\n",
        "plt.title(f'bs:{str(batch_size)} ')\n",
        "plt.legend();\n"
      ],
      "metadata": {
        "id": "NHjm_HXmEwC8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#save learning curve \n",
        "plt.savefig('learning_curve.png')"
      ],
      "metadata": {
        "id": "9hoUzP_BEx5j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from datetime import datetime\n",
        "from google.colab import files\n",
        "\n",
        "history_file_name = f'history/{datetime.now().strftime(\"history_%Y-%m-%d_%H-%M-%S\")}.json'\n",
        "out_file = open(history_file_name, \"w\")\n",
        "json.dump(history, out_file, indent=\"\")\n",
        "out_file.close()\n",
        "files.download(f\"/content/{history_file_name}\")\n",
        "#storage_upload_file(history_file_name)\n",
        "\n",
        "# save\n",
        "model.save('models/aug_eff_model')\n",
        "# save\n",
        "!zip -r /content/models/eff_model_colab.zip /content/models/aug_eff_model\n",
        "# download\n",
        "files.download(\"/content/models/eff_model_colab.zip\")\n",
        "#storage_upload_folder('models/aug_eff_model_test')"
      ],
      "metadata": {
        "id": "nk6oj2c2S8LQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Hint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode."
      ],
      "metadata": {
        "id": "PBjSEyrYPAoe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "lZCU3Y94W6li"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history['accuracy'], label = 'train')\n",
        "plt.plot(history['val_accuracy'], label = 'val')\n",
        "plt.title(f'')\n",
        "plt.legend();\n",
        "plt.savefig('learning_curve_accuracy.png')"
      ],
      "metadata": {
        "id": "7izjXHJ_C_0j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "y_pred = model.predict(train_ds.take(20))\n",
        "\n",
        "y_pred"
      ],
      "metadata": {
        "id": "tZfomkalqAzw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test_batch = train_ds.take(100)\n",
        "#test_batch[1]"
      ],
      "metadata": {
        "id": "hjZrJUCk95va"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#list(train_ds.as_numpy_iterator())[0]"
      ],
      "metadata": {
        "id": "ayjpcgWp-RdZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for example in train_ds.take(1).as_numpy_iterator():\n",
        "  print('X: ', example[0].shape)\n",
        "  print('Y: ', example[1].shape)"
      ],
      "metadata": {
        "id": "UhifSll2_g73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "rR7jOyIX9PNz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "5MNZOdfK_gRD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#classification_report(y_pred, )"
      ],
      "metadata": {
        "id": "Bj-pH10A5NfN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('max train accuracy', max(history['accuracy']))\n",
        "print('max val accuracy', max(history['val_accuracy']))"
      ],
      "metadata": {
        "id": "VRW-bKqLAPVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from cassava_farmer.trainer import Trainer\n",
        "# trainer = Trainer('colab')\n",
        "# trainer.train(data_path = 'gcs_bucket/cassava_farmer/train_images')"
      ],
      "metadata": {
        "id": "sE-LrJxNGaTT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "jOujAPUeJ2SD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # load previous history\n",
        "# import json\n",
        "\n",
        "# history = json.load(open('/content/history/history_2022-02-27_16-43-50'))\n",
        "\n",
        "# history"
      ],
      "metadata": {
        "id": "hVmXAU5gbW-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "label_map = {\n",
        "    '0': 'cassava_bacterial_blight', #1087\n",
        "    '1': 'cassava_brown_streak_disease', #2189\n",
        "    '2': 'cassava_green_mottle', #2386\n",
        "    '3': 'cassava_mosaic_disease', #13158\n",
        "    '4': 'healthy' #2577\n",
        "}"
      ],
      "metadata": {
        "id": "O93TdP1FREhy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_model = build_model()\n",
        "test_model.build((None, 512, 512, 3))\n",
        "test_model.summary()"
      ],
      "metadata": {
        "id": "a8dB-p-VuOTJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test_model = build_model()\n",
        "\n",
        "# history = test_model.fit(\n",
        "#                 train_ds,\n",
        "#                 epochs=1,\n",
        "#                 class_weights = class_weights\n",
        "#                 #batch_size=batch_size,\n",
        "#                 steps_per_epoch=steps_per_epoch,\n",
        "#                 validation_data=val_ds,\n",
        "#                 validation_steps=validation_steps,\n",
        "#                 validation_batch_size=batch_size).history\n",
        "#                 #callbacks=[es]"
      ],
      "metadata": {
        "id": "7qdQMs52Obpy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "EBBaLd9LOgbA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}