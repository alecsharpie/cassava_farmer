{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2480a6d9",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /Users/alecsharp/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (2.7.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/alecsharp/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/alecsharp/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /Users/alecsharp/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from tensorflow) (3.17.3)\n",
      "Requirement already satisfied: libclang>=9.0.1 in /Users/alecsharp/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from tensorflow) (12.0.0)\n",
      "Requirement already satisfied: tensorboard~=2.6 in /Users/alecsharp/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Users/alecsharp/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: gast<0.5.0,>=0.2.1 in /Users/alecsharp/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Users/alecsharp/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/alecsharp/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Users/alecsharp/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from tensorflow) (3.10.0.2)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Users/alecsharp/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Users/alecsharp/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.8,~=2.7.0rc0 in /Users/alecsharp/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: keras<2.8,>=2.7.0rc0 in /Users/alecsharp/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from tensorflow) (2.7.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.32.0 in /Users/alecsharp/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from tensorflow) (0.36.2)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /Users/alecsharp/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Users/alecsharp/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from tensorflow) (1.34.1)\n",
      "Requirement already satisfied: numpy>=1.14.5 in /Users/alecsharp/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from tensorflow) (1.19.2)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in /Users/alecsharp/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from tensorflow) (0.12.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /Users/alecsharp/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from tensorflow) (0.22.0)\n",
      "Requirement already satisfied: flatbuffers<3.0,>=1.12 in /Users/alecsharp/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /Users/alecsharp/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (49.2.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /Users/alecsharp/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (2.0.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /Users/alecsharp/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (0.4.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/alecsharp/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (2.26.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /Users/alecsharp/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /Users/alecsharp/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (1.33.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/alecsharp/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /Users/alecsharp/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from tensorboard~=2.6->tensorflow) (1.8.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/alecsharp/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /Users/alecsharp/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/alecsharp/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/alecsharp/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/alecsharp/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/alecsharp/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2021.5.30)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/alecsharp/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.26.6)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/alecsharp/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/alecsharp/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/alecsharp/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "987d5752",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc4271a",
   "metadata": {},
   "source": [
    "# organise data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ba802209",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000015157.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000201771.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100042118.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000723321.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000812911.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         image_id  label\n",
       "0  1000015157.jpg      0\n",
       "1  1000201771.jpg      3\n",
       "2   100042118.jpg      1\n",
       "3  1000723321.jpg      1\n",
       "4  1000812911.jpg      3"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../raw_data/cassava-leaf-disease-classification/train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "41eff8d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 3, 1, 2, 4])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45dd4962",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "57f38842",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': 'Cassava Bacterial Blight (CBB)',\n",
       " '1': 'Cassava Brown Streak Disease (CBSD)',\n",
       " '2': 'Cassava Green Mottle (CGM)',\n",
       " '3': 'Cassava Mosaic Disease (CMD)',\n",
       " '4': 'Healthy'}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "label_map = json.load(open('../raw_data/cassava-leaf-disease-classification/label_num_to_disease_map.json'))\n",
    "label_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "643f0354",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {'0': 'cassava_bacterial_blight',\n",
    " '1': 'cassava_brown_streak_disease',\n",
    " '2': 'cassava_green_mottle',\n",
    " '3': 'cassava_mosaic_disease',\n",
    " '4': 'healthy'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ce1e496d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label_text'] = df.label.astype(str).map(label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "99b186f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run once to reorganise images into folders of their class\n",
    "# create new folders\n",
    "#for label in label_map.values():\n",
    "#    os.mkdir(f'../raw_data/cassava-leaf-disease-classification/train_images/{label}')\n",
    "\n",
    "# for idx, row in df.iterrows():\n",
    "\n",
    "#     old_path = f\"../raw_data/cassava-leaf-disease-classification/train_images/{row['image_id']}\"\n",
    "#     new_path = f\"../raw_data/cassava-leaf-disease-classification/train_images/{row['label_text']}/{row['image_id']}\"\n",
    "    \n",
    "#     os.rename(old_path, new_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67db2bc9",
   "metadata": {},
   "source": [
    "# Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4e99e258",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_list = df.sort_values('image_id').label.values.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "bcf25f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 21397 files belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "#'/Users/alecsharp/me/cassava_farmer/raw_data/cassava-leaf-disease-classification/train_images'\n",
    "\n",
    "train_path = '../raw_data/cassava-leaf-disease-classification/train_images'\n",
    "\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "\n",
    "ds = image_dataset_from_directory(\n",
    "    train_path, batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da01880",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(path, subset):\n",
    "      return tf.keras.preprocessing.image_dataset_from_directory(\n",
    "          path,\n",
    "          validation_split=.20,\n",
    "          subset=subset,\n",
    "          label_mode=\"categorical\",\n",
    "          # Seed needs to provided when using validation_split and shuffle = True.\n",
    "          # A fixed seed is used so that the validation set is stable across runs.\n",
    "          seed=123,\n",
    "          image_size=IMAGE_SIZE,\n",
    "          batch_size=32)\n",
    "\n",
    "    train_ds = build_dataset(train_path, \"training\")\n",
    "    class_names = tuple(train_ds.class_names)\n",
    "    train_size = train_ds.cardinality().numpy()\n",
    "    train_ds = train_ds.unbatch().batch(BATCH_SIZE)\n",
    "    train_ds = train_ds.repeat()\n",
    "\n",
    "    normalization_layer = tf.keras.layers.Rescaling(1. / 255)\n",
    "    preprocessing_model = tf.keras.Sequential([normalization_layer])\n",
    "    \n",
    "    do_data_augmentation = True\n",
    "    \n",
    "    if do_data_augmentation:\n",
    "        preprocessing_model.add(\n",
    "            tf.keras.layers.RandomRotation(40))\n",
    "            preprocessing_model.add(\n",
    "            tf.keras.layers.RandomTranslation(0, 0.2))\n",
    "        preprocessing_model.add(\n",
    "            tf.keras.layers.RandomTranslation(0.2, 0))\n",
    "        # Like the old tf.keras.preprocessing.image.ImageDataGenerator(),\n",
    "        # image sizes are fixed when reading, and then a random zoom is applied.\n",
    "        # If all training inputs are larger than image_size, one could also use\n",
    "        # RandomCrop with a batch size of 1 and rebatch later.\n",
    "        preprocessing_model.add(\n",
    "            tf.keras.layers.RandomZoom(0.2, 0.2))\n",
    "        preprocessing_model.add(\n",
    "            tf.keras.layers.RandomFlip(mode=\"horizontal\"))\n",
    "    \n",
    "    train_ds = train_ds.map(lambda images, labels:\n",
    "                            (preprocessing_model(images), labels))\n",
    "\n",
    "    val_ds = build_dataset(\"validation\")\n",
    "    valid_size = val_ds.cardinality().numpy()\n",
    "    val_ds = val_ds.unbatch().batch(BATCH_SIZE)\n",
    "    val_ds = val_ds.map(lambda images, labels:\n",
    "                        (normalization_layer(images), labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e41b316",
   "metadata": {},
   "source": [
    "# Transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6430def2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow_hub\n",
      "  Downloading tensorflow_hub-0.12.0-py2.py3-none-any.whl (108 kB)\n",
      "     |████████████████████████████████| 108 kB 3.4 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.12.0 in /Users/alecsharp/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from tensorflow_hub) (1.19.2)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /Users/alecsharp/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from tensorflow_hub) (3.17.3)\n",
      "Requirement already satisfied: six>=1.9 in /Users/alecsharp/.pyenv/versions/3.8.6/envs/lewagon/lib/python3.8/site-packages (from protobuf>=3.8.0->tensorflow_hub) (1.15.0)\n",
      "Installing collected packages: tensorflow-hub\n",
      "Successfully installed tensorflow-hub-0.12.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "22e98996",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "957e5b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected model: efficientnetv2-b0 : https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_b0/feature_vector/2\n",
      "Input size (224, 224)\n"
     ]
    }
   ],
   "source": [
    "model_name = \"efficientnetv2-b0\" # @param ['efficientnetv2-s', 'efficientnetv2-m', 'efficientnetv2-l', 'efficientnetv2-s-21k', 'efficientnetv2-m-21k', 'efficientnetv2-l-21k', 'efficientnetv2-xl-21k', 'efficientnetv2-b0-21k', 'efficientnetv2-b1-21k', 'efficientnetv2-b2-21k', 'efficientnetv2-b3-21k', 'efficientnetv2-s-21k-ft1k', 'efficientnetv2-m-21k-ft1k', 'efficientnetv2-l-21k-ft1k', 'efficientnetv2-xl-21k-ft1k', 'efficientnetv2-b0-21k-ft1k', 'efficientnetv2-b1-21k-ft1k', 'efficientnetv2-b2-21k-ft1k', 'efficientnetv2-b3-21k-ft1k', 'efficientnetv2-b0', 'efficientnetv2-b1', 'efficientnetv2-b2', 'efficientnetv2-b3', 'efficientnet_b0', 'efficientnet_b1', 'efficientnet_b2', 'efficientnet_b3', 'efficientnet_b4', 'efficientnet_b5', 'efficientnet_b6', 'efficientnet_b7', 'bit_s-r50x1', 'inception_v3', 'inception_resnet_v2', 'resnet_v1_50', 'resnet_v1_101', 'resnet_v1_152', 'resnet_v2_50', 'resnet_v2_101', 'resnet_v2_152', 'nasnet_large', 'nasnet_mobile', 'pnasnet_large', 'mobilenet_v2_100_224', 'mobilenet_v2_130_224', 'mobilenet_v2_140_224', 'mobilenet_v3_small_100_224', 'mobilenet_v3_small_075_224', 'mobilenet_v3_large_100_224', 'mobilenet_v3_large_075_224']\n",
    "\n",
    "model_handle_map = {\n",
    "  \"efficientnetv2-s\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_s/feature_vector/2\",\n",
    "  \"efficientnetv2-m\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_m/feature_vector/2\",\n",
    "  \"efficientnetv2-l\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_l/feature_vector/2\",\n",
    "  \"efficientnetv2-s-21k\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_s/feature_vector/2\",\n",
    "  \"efficientnetv2-m-21k\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_m/feature_vector/2\",\n",
    "  \"efficientnetv2-l-21k\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_l/feature_vector/2\",\n",
    "  \"efficientnetv2-xl-21k\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_xl/feature_vector/2\",\n",
    "  \"efficientnetv2-b0-21k\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_b0/feature_vector/2\",\n",
    "  \"efficientnetv2-b1-21k\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_b1/feature_vector/2\",\n",
    "  \"efficientnetv2-b2-21k\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_b2/feature_vector/2\",\n",
    "  \"efficientnetv2-b3-21k\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_b3/feature_vector/2\",\n",
    "  \"efficientnetv2-s-21k-ft1k\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_ft1k_s/feature_vector/2\",\n",
    "  \"efficientnetv2-m-21k-ft1k\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_ft1k_m/feature_vector/2\",\n",
    "  \"efficientnetv2-l-21k-ft1k\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_ft1k_l/feature_vector/2\",\n",
    "  \"efficientnetv2-xl-21k-ft1k\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_ft1k_xl/feature_vector/2\",\n",
    "  \"efficientnetv2-b0-21k-ft1k\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_ft1k_b0/feature_vector/2\",\n",
    "  \"efficientnetv2-b1-21k-ft1k\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_ft1k_b1/feature_vector/2\",\n",
    "  \"efficientnetv2-b2-21k-ft1k\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_ft1k_b2/feature_vector/2\",\n",
    "  \"efficientnetv2-b3-21k-ft1k\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet21k_ft1k_b3/feature_vector/2\",\n",
    "  \"efficientnetv2-b0\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_b0/feature_vector/2\",\n",
    "  \"efficientnetv2-b1\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_b1/feature_vector/2\",\n",
    "  \"efficientnetv2-b2\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_b2/feature_vector/2\",\n",
    "  \"efficientnetv2-b3\": \"https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_b3/feature_vector/2\",\n",
    "  \"efficientnet_b0\": \"https://tfhub.dev/tensorflow/efficientnet/b0/feature-vector/1\",\n",
    "  \"efficientnet_b1\": \"https://tfhub.dev/tensorflow/efficientnet/b1/feature-vector/1\",\n",
    "  \"efficientnet_b2\": \"https://tfhub.dev/tensorflow/efficientnet/b2/feature-vector/1\",\n",
    "  \"efficientnet_b3\": \"https://tfhub.dev/tensorflow/efficientnet/b3/feature-vector/1\",\n",
    "  \"efficientnet_b4\": \"https://tfhub.dev/tensorflow/efficientnet/b4/feature-vector/1\",\n",
    "  \"efficientnet_b5\": \"https://tfhub.dev/tensorflow/efficientnet/b5/feature-vector/1\",\n",
    "  \"efficientnet_b6\": \"https://tfhub.dev/tensorflow/efficientnet/b6/feature-vector/1\",\n",
    "  \"efficientnet_b7\": \"https://tfhub.dev/tensorflow/efficientnet/b7/feature-vector/1\",\n",
    "  \"bit_s-r50x1\": \"https://tfhub.dev/google/bit/s-r50x1/1\",\n",
    "  \"inception_v3\": \"https://tfhub.dev/google/imagenet/inception_v3/feature-vector/4\",\n",
    "  \"inception_resnet_v2\": \"https://tfhub.dev/google/imagenet/inception_resnet_v2/feature-vector/4\",\n",
    "  \"resnet_v1_50\": \"https://tfhub.dev/google/imagenet/resnet_v1_50/feature-vector/4\",\n",
    "  \"resnet_v1_101\": \"https://tfhub.dev/google/imagenet/resnet_v1_101/feature-vector/4\",\n",
    "  \"resnet_v1_152\": \"https://tfhub.dev/google/imagenet/resnet_v1_152/feature-vector/4\",\n",
    "  \"resnet_v2_50\": \"https://tfhub.dev/google/imagenet/resnet_v2_50/feature-vector/4\",\n",
    "  \"resnet_v2_101\": \"https://tfhub.dev/google/imagenet/resnet_v2_101/feature-vector/4\",\n",
    "  \"resnet_v2_152\": \"https://tfhub.dev/google/imagenet/resnet_v2_152/feature-vector/4\",\n",
    "  \"nasnet_large\": \"https://tfhub.dev/google/imagenet/nasnet_large/feature_vector/4\",\n",
    "  \"nasnet_mobile\": \"https://tfhub.dev/google/imagenet/nasnet_mobile/feature_vector/4\",\n",
    "  \"pnasnet_large\": \"https://tfhub.dev/google/imagenet/pnasnet_large/feature_vector/4\",\n",
    "  \"mobilenet_v2_100_224\": \"https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/4\",\n",
    "  \"mobilenet_v2_130_224\": \"https://tfhub.dev/google/imagenet/mobilenet_v2_130_224/feature_vector/4\",\n",
    "  \"mobilenet_v2_140_224\": \"https://tfhub.dev/google/imagenet/mobilenet_v2_140_224/feature_vector/4\",\n",
    "  \"mobilenet_v3_small_100_224\": \"https://tfhub.dev/google/imagenet/mobilenet_v3_small_100_224/feature_vector/5\",\n",
    "  \"mobilenet_v3_small_075_224\": \"https://tfhub.dev/google/imagenet/mobilenet_v3_small_075_224/feature_vector/5\",\n",
    "  \"mobilenet_v3_large_100_224\": \"https://tfhub.dev/google/imagenet/mobilenet_v3_large_100_224/feature_vector/5\",\n",
    "  \"mobilenet_v3_large_075_224\": \"https://tfhub.dev/google/imagenet/mobilenet_v3_large_075_224/feature_vector/5\",\n",
    "}\n",
    "\n",
    "model_image_size_map = {\n",
    "  \"efficientnetv2-s\": 384,\n",
    "  \"efficientnetv2-m\": 480,\n",
    "  \"efficientnetv2-l\": 480,\n",
    "  \"efficientnetv2-b0\": 224,\n",
    "  \"efficientnetv2-b1\": 240,\n",
    "  \"efficientnetv2-b2\": 260,\n",
    "  \"efficientnetv2-b3\": 300,\n",
    "  \"efficientnetv2-s-21k\": 384,\n",
    "  \"efficientnetv2-m-21k\": 480,\n",
    "  \"efficientnetv2-l-21k\": 480,\n",
    "  \"efficientnetv2-xl-21k\": 512,\n",
    "  \"efficientnetv2-b0-21k\": 224,\n",
    "  \"efficientnetv2-b1-21k\": 240,\n",
    "  \"efficientnetv2-b2-21k\": 260,\n",
    "  \"efficientnetv2-b3-21k\": 300,\n",
    "  \"efficientnetv2-s-21k-ft1k\": 384,\n",
    "  \"efficientnetv2-m-21k-ft1k\": 480,\n",
    "  \"efficientnetv2-l-21k-ft1k\": 480,\n",
    "  \"efficientnetv2-xl-21k-ft1k\": 512,\n",
    "  \"efficientnetv2-b0-21k-ft1k\": 224,\n",
    "  \"efficientnetv2-b1-21k-ft1k\": 240,\n",
    "  \"efficientnetv2-b2-21k-ft1k\": 260,\n",
    "  \"efficientnetv2-b3-21k-ft1k\": 300, \n",
    "  \"efficientnet_b0\": 224,\n",
    "  \"efficientnet_b1\": 240,\n",
    "  \"efficientnet_b2\": 260,\n",
    "  \"efficientnet_b3\": 300,\n",
    "  \"efficientnet_b4\": 380,\n",
    "  \"efficientnet_b5\": 456,\n",
    "  \"efficientnet_b6\": 528,\n",
    "  \"efficientnet_b7\": 600,\n",
    "  \"inception_v3\": 299,\n",
    "  \"inception_resnet_v2\": 299,\n",
    "  \"nasnet_large\": 331,\n",
    "  \"pnasnet_large\": 331,\n",
    "}\n",
    "\n",
    "model_handle = model_handle_map.get(model_name)\n",
    "pixels = model_image_size_map.get(model_name, 224)\n",
    "\n",
    "print(f\"Selected model: {model_name} : {model_handle}\")\n",
    "\n",
    "IMAGE_SIZE = (pixels, pixels)\n",
    "print(f\"Input size {IMAGE_SIZE}\")\n",
    "\n",
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "774254d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = hub.load(model_handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54536cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Building model with\", model_handle)\n",
    "model = tf.keras.Sequential([\n",
    "    # Explicitly define the input shape so the model can be properly\n",
    "    # loaded by the TFLiteConverter\n",
    "    tf.keras.layers.InputLayer(input_shape=IMAGE_SIZE + (3,)),\n",
    "    hub.KerasLayer(model_handle, trainable=do_fine_tuning),\n",
    "    tf.keras.layers.Dropout(rate=0.2),\n",
    "    tf.keras.layers.Dense(len(class_names),\n",
    "                          kernel_regularizer=tf.keras.regularizers.l2(0.0001))\n",
    "])\n",
    "model.build((None,)+IMAGE_SIZE+(3,))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6cf2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  optimizer=tf.keras.optimizers.SGD(learning_rate=0.005, momentum=0.9), \n",
    "  loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True, label_smoothing=0.1),\n",
    "  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf23c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps_per_epoch = train_size // BATCH_SIZE\n",
    "validation_steps = valid_size // BATCH_SIZE\n",
    "hist = model.fit(\n",
    "    train_ds,\n",
    "    epochs=5, steps_per_epoch=steps_per_epoch,\n",
    "    validation_data=val_ds,\n",
    "    validation_steps=validation_steps).history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
